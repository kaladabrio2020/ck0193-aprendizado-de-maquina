# -*- coding: utf-8 -*-
"""lista_2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1bE4ZmwfPDGGoGMISzczq0pTVEpvI6QS9
"""

import numpy as np
import pandas as pd
from sklearn.metrics import accuracy_score, confusion_matrix
from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import train_test_split, ShuffleSplit
from sklearn.preprocessing   import StandardScaler

"""Questão 1"""

data = pd.read_csv('/content/breastcancer.csv', header=None)
data.head()

data[30].unique()

data.corrwith(other=data[30])

data.describe()

x, y = data.iloc[:, :-1].values, data.iloc[:, -1].values

"""a.

Logistica
"""

class Logistica:
    def __init__(self, x, y):
        self.log = LogisticRegression()
        self.log.fit(x, y)

    def predict(self, x):
        return self.log.predict(x)

"""Análise do discriminante Gaussiano"""

class GaussianDiscriminantAnalysis:
    def __init__(self, X, y):
        self.classes = np.unique(y)
        n, d = X.shape
        self.medias = {}
        self.priores = {}
        self.covariancia = np.zeros((d, d))

        for c in self.classes:
            X_c = X[y == c]
            self.medias[c] = np.mean(X_c, axis=0)
            self.priores[c] = X_c.shape[0] / n
            self.covariancia += (X_c.shape[0] / n) * np.cov(X_c, rowvar=False)

        self.cov_inv = np.linalg.inv(self.covariancia)

    def predict(self, X):
        previsoes = []
        for x in X:
            escores = {}
            for c in self.classes:
                media = self.medias[c]
                prior = self.priores[c]
                score = (
                    -0.5 * np.dot((x - media).T, np.dot(self.cov_inv, (x - media)))
                    + np.log(prior)
                )
                escores[c] = score
            previsoes.append(max(escores, key=escores.get))
        return np.array(previsoes)

"""Naive Bayes Gaussiano"""

class GaussianNaiveBayes:
    def __init__(self, X, y):
        self.classes = np.unique(y)
        self.medias = {}
        self.variancias = {}
        self.priores = {}

        for c in self.classes:
            X_c = X[y == c]
            self.medias[c] = np.mean(X_c, axis=0)
            self.variancias[c] = np.var(X_c, axis=0)
            self.priores[c] = X_c.shape[0] / X.shape[0]

    def gaussian_pdf(self, x, mean, var):
        expoente = np.exp(- (x - mean) ** 2 / (2 * var))
        return (1 / np.sqrt(2 * np.pi * var)) * expoente

    def predict(self, X):
        previsoes = []
        for x in X:
            posteriors = []
            for c in self.classes:
                prior = np.log(self.priores[c])
                cond = np.sum(np.log(self.gaussian_pdf(x, self.medias[c], self.variancias[c])))
                posteriors.append(prior + cond)
            previsoes.append(self.classes[np.argmax(posteriors)])
        return np.array(previsoes)

"""Validação cruzada"""

def validacao_cruzada(x, y, k=10, models=Logistica):
    ss = ShuffleSplit(n_splits=k, test_size=0.2, random_state=0)

    accuracies = []
    acuracia_por_classes = []
    for train_index, test_index in ss.split(x):
        x_train, x_test = x[train_index], x[test_index]
        y_train, y_test = y[train_index], y[test_index]

        # Escalonando features
        scaler = StandardScaler()
        x_train = scaler.fit_transform(x_train)
        x_test = scaler.transform(x_test)

        # Treinando modelo
        model = models(x_train, y_train)

        # predição
        pred = model.predict(x_test)

        # Acurácia
        accuracy = accuracy_score(y_test, pred)

        accuracies.append(accuracy)

        # Acurácia por classe
        cm = confusion_matrix(y_test, pred)
        acuracia_classe = cm.diagonal() / cm.sum(axis=1)
        acuracia_por_classes.append(acuracia_classe)
    return accuracies, acuracia_por_classes

"""b"""

def avaliar_modelo(x, y, modelo_class, nome_modelo):
    accuracies, acc_class = validacao_cruzada(x, y, k=10, models=modelo_class)

    media_global = np.mean(accuracies)
    desvio_global = np.std(accuracies)

    # Pad acc_class with NaNs to ensure all arrays have the same length
    max_len = max(len(arr) for arr in acc_class)
    acc_class_padded = [np.pad(arr, (0, max_len - len(arr)), 'constant', constant_values=np.nan) for arr in acc_class]

    acc_class = np.array(acc_class_padded)
    medias_classe = np.nanmean(acc_class, axis=0) # Use nanmean to ignore NaNs
    desvios_classe = np.nanstd(acc_class, axis=0) # Use nanstd to ignore NaNs

    print(f"Modelo: {nome_modelo}")
    print(f"Acurácia global média: {media_global:.4f} ± {desvio_global:.4f}")
    for i, (m, d) in enumerate(zip(medias_classe, desvios_classe)):
        print(f"  Classe {i}: {m:.4f} ± {d:.4f}")

    return {
        "nome": nome_modelo,
        "acuracias": accuracies,
        "media_global": media_global,
        "desvio_global": desvio_global,
        "medias_classe": medias_classe,
        "desvios_classe": desvios_classe
    }

# Avaliar os três modelos
resultados = []
resultados.append(avaliar_modelo(x, y, Logistica, "Regressão Logística"))
resultados.append(avaliar_modelo(x, y, GaussianDiscriminantAnalysis, "GDA"))
resultados.append(avaliar_modelo(x, y, GaussianNaiveBayes, "Naive Bayes"))

"""Questão 2"""

data = pd.read_csv('/content/vehicle.csv', header=None)
data.head()

x = data.iloc[:, :-1].values
y = data.iloc[:, -1].values

"""a."""

class SoftmaxRegression:
    def __init__(self, x, y, lr=0.01, epochs=1000):
        self.lr = lr
        self.epochs = epochs
        self.fit(x, y)
    def softmax(self, z):
        exp_z = np.exp(z - np.max(z, axis=1, keepdims=True))
        return exp_z / np.sum(exp_z, axis=1, keepdims=True)

    def fit(self, X, y):
        n, d = X.shape
        classes = np.unique(y)
        k = len(classes)
        self.classes = classes
        y_onehot = np.zeros((n, k))
        for i, c in enumerate(classes):
            y_onehot[:, i] = (y == c).astype(int)

        self.W = np.zeros((d, k))
        self.b = np.zeros((1, k))

        for _ in range(self.epochs):
            z = np.dot(X, self.W) + self.b
            probs = self.softmax(z)

            dW = (1/n) * np.dot(X.T, (probs - y_onehot))
            db = (1/n) * np.sum(probs - y_onehot, axis=0, keepdims=True)

            self.W -= self.lr * dW
            self.b -= self.lr * db

    def predict(self, X):
        z = np.dot(X, self.W) + self.b
        probs = self.softmax(z)
        preds = np.argmax(probs, axis=1)
        return self.classes[preds]

"""b"""

# Avaliar os três modelos
resultados = []
resultados.append(avaliar_modelo(x, y, Logistica, "SoftMax"))
resultados.append(avaliar_modelo(x, y, GaussianDiscriminantAnalysis, "GDA"))
resultados.append(avaliar_modelo(x, y, GaussianNaiveBayes, "Naive Bayes"))

